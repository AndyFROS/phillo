## **1. Параметры сервера**

### Общие настройки:

- `--host`: Указывает адрес хоста для сервера.
- `--port`: Порт, на котором сервер будет принимать запросы.
- `--uvicorn-log-level`: Уровень логирования Uvicorn (`debug`, `info`, `warning`, `error`, `critical`, `trace`).

### Безопасность и доступ:

- `--allow-credentials`: Разрешает передачу учетных данных (cookies).
- `--allowed-origins`: Разрешенные источники для CORS.
- `--allowed-methods`: Список допустимых HTTP-методов.
- `--allowed-headers`: Указывает разрешенные заголовки.
- `--api-key`: Устанавливает API-ключ для аутентификации запросов.

### SSL-настройки:

- `--ssl-keyfile`: Путь к SSL-ключу.
- `--ssl-certfile`: Путь к SSL-сертификату.
- `--ssl-ca-certs`: Путь к сертификатам доверенных центров сертификации (CA).
- `--ssl-cert-reqs`: Уровень требований к сертификатам (`none`, `optional`, `required`).

### Прочие параметры:

- `--root-path`: Устанавливает корневой путь приложения.
- `--middleware`: Список промежуточного ПО.
- `--disable-log-requests`: Отключает логирование запросов.
- `--max-log-len`: Максимальная длина логов.

---

## **2. Параметры модели**

### Загрузка модели:

- `--model`: Имя или путь к модели.
- `--served-model-name`: Имя сервируемой модели.
- `--revision`: Версия модели.
- `--code-revision`: Версия кода модели.
- `--trust-remote-code`: Разрешает загрузку удаленного кода.
- `--download-dir`: Каталог для загрузки модели.
- `--load-format`: Формат загрузки (`auto`, `pt`, `safetensors`, и др.).
- `--model-loader-extra-config`: Дополнительная конфигурация загрузчика модели.

### Токенизатор:

- `--tokenizer`: Указывает путь или имя токенизатора.
- `--tokenizer-revision`: Версия токенизатора.
- `--tokenizer-mode`: Режим токенизатора (`auto`, `slow`).
- `--skip-tokenizer-init`: Пропускает инициализацию токенизатора.
- `--tokenizer-pool-size`: Размер пула токенизаторов.
- `--tokenizer-pool-type`: Тип пула токенизаторов.
- `--tokenizer-pool-extra-config`: Дополнительная конфигурация пула токенизаторов.

### LoRA (Low-Rank Adaptation):

- `--enable-lora`: Включает поддержку LoRA.
- `--lora-modules`: Список модулей LoRA.
- `--max-loras`: Максимальное количество LoRA.
- `--max-lora-rank`: Максимальный ранг LoRA.
- `--lora-extra-vocab-size`: Дополнительный размер словаря для LoRA.
- `--lora-dtype`: Тип данных для LoRA (`float16`, `bfloat16`).
- `--max-cpu-loras`: Максимальное количество LoRA на CPU.

---

## **3. Производительность и оптимизация**

### Параллелизм:

- `--pipeline-parallel-size`: Уровень параллелизма конвейера.
- `--tensor-parallel-size`: Уровень тензорного параллелизма.
- `--distributed-executor-backend`: Бэкенд для распределенного выполнения (`ray`, `mp` и др.).
- `--worker-use-ray`: Использование Ray для рабочих процессов.
- `--ray-workers-use-nsight`: Использует Nsight для анализа производительности.

### Память:

- `--gpu-memory-utilization`: Уровень использования памяти GPU.
- `--cpu-offload-gb`: Объем памяти CPU для выгрузки данных.
- `--swap-space`: Объем пространства подкачки.
- `--num-gpu-blocks-override`: Переопределение числа блоков GPU.

### Настройки модели:

- `--dtype`: Тип данных модели (`float16`, `bfloat16`, и др.).
- `--kv-cache-dtype`: Тип данных для кэша ключ-значение.
- `--quantization`: Тип квантизации (`aqlm`, `gptq`, и др.).
- `--quantization-param-path`: Путь к параметрам квантизации.
- `--max-model-len`: Максимальная длина модели.
- `--block-size`: Размер блока (8, 16, 32).

### Производительность обработки:

- `--max-num-batched-tokens`: Максимальное число токенов в одном батче.
- `--max-num-seqs`: Максимальное число обрабатываемых последовательностей.
- `--max-logprobs`: Максимальное количество логарифмов вероятностей.
- `--max-context-len-to-capture`: Максимальная длина контекста для анализа.
- `--enable-prefix-caching`: Включает кэширование префиксов.
- `--num-lookahead-slots`: Число слотов для предсказания.
- `--enforce-eager`: Включает "жадный" режим вычислений.

---

## **4. Настройка чата**

- `--chat-template`: Путь к шаблону чата.
- `--response-role`: Роль ответа в чате.
- `--enable-chunked-prefill`: Включает разбиение данных при предварительной загрузке.

---

## **5. Настройки для работы с изображениями**

- `--image-input-type`: Тип входного изображения (`pixel_values`, `image_features`).
- `--image-token-id`: Идентификатор токена для изображений.
- `--image-input-shape`: Форма входного изображения.
- `--image-feature-size`: Размер признаков изображения.

---

## **6. Логирование и отладка**

- `--disable-log-stats`: Отключает статистику логов.
- `--log-format`: Формат логов.
- `--trace-log-directory`: Директория для хранения логов.

---

## **7. Спекулятивное исполнение**

- `--speculative-model`: Указывает модель для спекулятивного исполнения.
- `--num-speculative-tokens`: Число спекулятивных токенов.
- `--speculative-max-model-len`: Максимальная длина модели для спекулятивного исполнения.

---

## **8. Прочие параметры**

- `--seed`: Устанавливает начальное значение для генератора случайных чисел.
- `--scheduler-delay-factor`: Фактор задержки планировщика.
- `--use-v2-block-manager`: Использует менеджер блоков версии 2.
- `--disable-custom-all-reduce`: Отключает пользовательский метод `all-reduce`.



# Более подробное описание

## **1. Параметры сервера**

### **Общие настройки**

1. **`--host`**
    
    - **Описание**: Определяет, на каком адресе хост будет прослушивать входящие запросы.
    - **Пример значения**:
        - `127.0.0.1` (только локальные подключения),
        - `0.0.0.0` (все сетевые интерфейсы).
    - **Когда использовать**: Если сервер используется только для локальной разработки, оставьте значение `127.0.0.1`. Если сервер нужно сделать доступным из других устройств в сети, используйте `0.0.0.0`.
2. **`--port`**
    
    - **Описание**: Указывает номер порта, на котором сервер будет принимать запросы.
    - **Пример значения**: `8000` (по умолчанию).
    - **Когда использовать**: Если у вас уже используется порт 8000 для другого сервиса, укажите свободный порт, например, `8080`.
3. **`--uvicorn-log-level`**
    
    - **Описание**: Задает уровень детализации логов сервера.
    - **Допустимые значения**:
        - `debug`: Показывает самые подробные сообщения, полезно для отладки.
        - `info`: Выводит основную информацию о работе сервера.
        - `warning`: Показывает предупреждения, которые могут повлиять на работу.
        - `error`: Сообщает только о серьезных ошибках.
        - `critical`: Указывает на критические проблемы.
    - **Когда использовать**:
        - Для отладки — `debug`.
        - Для продакшена — `info` или `warning`.

---

### **Безопасность и доступ**

4. **`--allow-credentials`**
    
    - **Описание**: Если включено, сервер позволяет отправлять учетные данные (например, cookies) в запросах.
    - **Когда использовать**:
        - Если ваш клиент (браузер или приложение) работает с авторизацией через cookies.
5. **`--allowed-origins`**
    
    - **Описание**: Указывает список источников (доменов), которые могут отправлять запросы к серверу.
    - **Пример значения**:
        - `https://example.com` — разрешить доступ только с этого домена.
        - `*` — разрешить доступ с любого источника (не рекомендуется для продакшена).
    - **Когда использовать**:
        - Если сервер обслуживает веб-приложение, обязательно добавьте домен этого приложения.
6. **`--allowed-methods`**
    
    - **Описание**: Определяет HTTP-методы, которые сервер принимает.
    - **Пример значения**:
        - `GET, POST` — разрешить только чтение данных и отправку запросов.
        - `*` — разрешить любые методы.
    - **Когда использовать**: Для API обычно достаточно методов `GET`, `POST`, `OPTIONS`.
7. **`--allowed-headers`**
    
    - **Описание**: Указывает, какие HTTP-заголовки могут использоваться в запросах.
    - **Пример значения**:
        - `Content-Type, Authorization` — разрешить только заголовки с типом содержимого и авторизацией.
        - `*` — разрешить любые заголовки.
    - **Когда использовать**: Для работы с клиентами (например, браузерами) важно разрешить заголовки, используемые для авторизации и отправки данных.
8. **`--api-key`**
    
    - **Описание**: Устанавливает API-ключ для аутентификации запросов.
    - **Пример значения**: `my_secret_api_key`.
    - **Когда использовать**:
        - Если хотите ограничить доступ к серверу только клиентам с правильным ключом.
        - Клиенты должны добавлять ключ в заголовок запроса, например: `Authorization: Bearer my_secret_api_key`.

---

### **SSL-настройки**

9. **`--ssl-keyfile`**
    
    - **Описание**: Указывает путь к файлу с закрытым ключом для шифрования соединения.
    - **Пример значения**: `/path/to/ssl-key.pem`.
    - **Когда использовать**: Если вы хотите запустить сервер по протоколу HTTPS.
10. **`--ssl-certfile`**
    
    - **Описание**: Указывает путь к SSL-сертификату.
    - **Пример значения**: `/path/to/ssl-cert.pem`.
    - **Когда использовать**: Если используете HTTPS, сертификат обязателен.
11. **`--ssl-ca-certs`**
    
    - **Описание**: Указывает файл доверенных центров сертификации (CA), который сервер использует для проверки клиентских сертификатов.
    - **Пример значения**: `/path/to/ca-certs.pem`.
    - **Когда использовать**: В случаях, когда клиенты также должны предоставлять сертификаты для двустороннего шифрования.
12. **`--ssl-cert-reqs`**
    
    - **Описание**: Определяет, требуется ли клиентский сертификат.
    - **Допустимые значения**:
        - `none`: Клиентские сертификаты не требуются.
        - `optional`: Сертификаты принимаются, но не обязательны.
        - `required`: Сертификаты обязательны.
    - **Когда использовать**: Включите `required`, если требуется двустороннее шифрование (например, для внутреннего API).

---

### **Прочие параметры**

13. **`--root-path`**
    
    - **Описание**: Устанавливает базовый URL для сервера.
    - **Пример значения**: `/api/v1`.
    - **Когда использовать**: Если сервер развернут за обратным прокси (например, Nginx) и требует базового пути.
14. **`--middleware`**
    
    - **Описание**: Указывает промежуточное ПО (middleware), которое будет обрабатывать запросы перед их передачей серверу.
    - **Пример значения**: `logging, authentication`.
    - **Когда использовать**: Для добавления дополнительных функций, таких как логирование, аутентификация или обработка CORS.
15. **`--disable-log-requests`**
    
    - **Описание**: Отключает запись запросов в логи.
    - **Когда использовать**: Если не хотите, чтобы логи сервера включали запросы (например, для уменьшения нагрузки).
16. **`--max-log-len`**
    
    - **Описание**: Устанавливает максимальную длину логов для одного запроса.
    - **Пример значения**: `1000`.
    - **Когда использовать**: Для ограничения объема информации в логах (например, если клиентские запросы содержат большие данные).




### **2. Параметры модели**

Параметры в этой группе определяют, какую модель загружать, как работать с её настройками и какие дополнительные возможности использовать (например, токенизаторы и LoRA). Эти параметры важны для настройки серверов, работающих с нейросетевыми моделями.

---

### **Загрузка модели**

1. **`--model`**
    
    - **Описание**: Указывает имя или путь к модели, которую необходимо загрузить.
    - **Пример значения**:
        - Имя модели: `gpt-neo-1.3B`.
        - Локальный путь: `/path/to/model/`.
    - **Когда использовать**: Всегда, так как это основной параметр для указания модели.
2. **`--served-model-name`**
    
    - **Описание**: Имя модели, под которым она будет доступна клиентам через API.
    - **Пример значения**: `openai-gpt3`.
    - **Когда использовать**: Если требуется дать модели "человеческое" имя для удобства использования.
3. **`--revision`**
    
    - **Описание**: Указывает версию модели, если доступны несколько версий.
    - **Пример значения**: `main` или `v1.0.0`.
    - **Когда использовать**: Если работаете с репозиториями, содержащими несколько версий модели.
4. **`--code-revision`**
    
    - **Описание**: Версия кода модели, используемого для загрузки.
    - **Пример значения**: `v1.0.0`.
    - **Когда использовать**: Когда модель содержит специфичный код для определенных версий.
5. **`--trust-remote-code`**
    
    - **Описание**: Разрешает загрузку и выполнение удаленного кода, связанного с моделью.
    - **Когда использовать**: Только если вы доверяете источнику модели (например, при загрузке с официальных репозиториев).
6. **`--download-dir`**
    
    - **Описание**: Указывает каталог для загрузки модели и связанных файлов.
    - **Пример значения**: `/data/models/`.
    - **Когда использовать**: Если вы хотите сохранить модели в определенном месте (например, для экономии места на основном диске).
7. **`--load-format`**
    
    - **Описание**: Формат загрузки модели.
    - **Допустимые значения**:
        - `auto`: Определяется автоматически.
        - `pt`: PyTorch-формат.
        - `safetensors`: Безопасный бинарный формат.
    - **Когда использовать**: Если нужно явно указать формат модели.
8. **`--model-loader-extra-config`**
    
    - **Описание**: Дополнительная конфигурация для загрузчика модели.
    - **Пример значения**: JSON-строка с настройками.
    - **Когда использовать**: Для сложных настроек загрузки.

---

### **Токенизатор**

9. **`--tokenizer`**
    
    - **Описание**: Указывает путь или имя токенизатора.
    - **Пример значения**:
        - Имя: `gpt2-tokenizer`.
        - Путь: `/path/to/tokenizer/`.
    - **Когда использовать**: Если токенизатор отличается от используемой модели.
10. **`--tokenizer-revision`**
    
    - **Описание**: Указывает версию токенизатора.
    - **Пример значения**: `main` или `v1.0.0`.
    - **Когда использовать**: Если работаете с несколькими версиями токенизатора.
11. **`--tokenizer-mode`**
    
    - **Описание**: Режим работы токенизатора.
    - **Допустимые значения**:
        - `auto`: Определяется автоматически.
        - `slow`: Использует более медленный режим токенизации.
    - **Когда использовать**: Если требуется явное указание режима работы токенизатора.
12. **`--skip-tokenizer-init`**
    
    - **Описание**: Пропускает инициализацию токенизатора при запуске.
    - **Когда использовать**: Для ускорения загрузки модели, если токенизатор не используется.
13. **`--tokenizer-pool-size`**
    
    - **Описание**: Размер пула токенизаторов.
    - **Пример значения**: `4` (одновременное использование 4 токенизаторов).
    - **Когда использовать**: Для многопоточной обработки запросов.
14. **`--tokenizer-pool-type`**
    
    - **Описание**: Тип пула токенизаторов.
    - **Пример значения**: `thread` (использование потоков).
    - **Когда использовать**: Если требуется явный контроль над пулом.
15. **`--tokenizer-pool-extra-config`**
    
    - **Описание**: Дополнительная конфигурация пула токенизаторов.
    - **Пример значения**: JSON-строка с параметрами.
    - **Когда использовать**: Для специфичных требований к пулу токенизаторов.

---

### **LoRA (Low-Rank Adaptation)**

16. **`--enable-lora`**
    
    - **Описание**: Включает поддержку адаптации модели с использованием LoRA.
    - **Когда использовать**: Если вы хотите ускорить обучение модели для новой задачи.
17. **`--lora-modules`**
    
    - **Описание**: Список модулей LoRA, которые будут использоваться.
    - **Пример значения**: `module1, module2`.
    - **Когда использовать**: Если нужно адаптировать только определенные части модели.
18. **`--max-loras`**
    
    - **Описание**: Максимальное количество LoRA, которое можно подключить.
    - **Пример значения**: `4`.
    - **Когда использовать**: Для ограничения количества активных модулей LoRA.
19. **`--max-lora-rank`**
    
    - **Описание**: Максимальный ранг (ранг матрицы) для LoRA.
    - **Пример значения**: `16`.
    - **Когда использовать**: Для контроля сложности адаптации.
20. **`--lora-extra-vocab-size`**
    
    - **Описание**: Дополнительный размер словаря для LoRA.
    - **Пример значения**: `100`.
    - **Когда использовать**: Если требуется расширить словарь модели для новой задачи.
21. **`--lora-dtype`**
    
    - **Описание**: Тип данных для LoRA.
    - **Допустимые значения**: `float16`, `bfloat16`, `float32`.
    - **Когда использовать**: Если нужно оптимизировать использование памяти.
22. **`--max-cpu-loras`**
    
    - **Описание**: Максимальное количество LoRA, размещаемое на CPU.
    - **Пример значения**: `2`.
    - **Когда использовать**: Для оптимизации работы на системах с ограниченной памятью GPU.




### **3. Производительность и оптимизация**

Эта группа параметров отвечает за настройку производительности сервера, управление памятью, параллельным выполнением и другими аспектами, которые влияют на скорость работы и использование ресурсов.

---

### **Параллелизм**

1. **`--pipeline-parallel-size`**
    
    - **Описание**: Определяет уровень параллелизма конвейера. Это означает разделение обработки между несколькими устройствами (например, GPU).
    - **Пример значения**: `2` (разделение между 2 GPU).
    - **Когда использовать**: Если модель большая и требует распределения нагрузки.
2. **`--tensor-parallel-size`**
    
    - **Описание**: Уровень параллелизма на уровне тензоров. Модель разделяется по слоям и обрабатывается одновременно.
    - **Пример значения**: `4`.
    - **Когда использовать**: Для ускорения вычислений на нескольких GPU.
3. **`--distributed-executor-backend`**
    
    - **Описание**: Определяет бэкенд для распределенной работы.
    - **Допустимые значения**:
        - `ray`: Использует Ray для распределения.
        - `mp`: Использует multiprocessing (многопроцессорность).
    - **Когда использовать**: Если сервер работает в распределенной системе (например, кластер GPU).
4. **`--worker-use-ray`**
    
    - **Описание**: Включает использование Ray для управления рабочими процессами.
    - **Когда использовать**: Если требуется масштабирование с помощью Ray.
5. **`--ray-workers-use-nsight`**
    
    - **Описание**: Использует Nsight для профилирования рабочих процессов Ray.
    - **Когда использовать**: Для отладки и анализа производительности.

---

### **Память**

6. **`--gpu-memory-utilization`**
    
    - **Описание**: Устанавливает максимальный уровень использования памяти GPU.
    - **Пример значения**: `0.8` (использование 80% памяти).
    - **Когда использовать**: Для предотвращения переполнения памяти на GPU.
7. **`--cpu-offload-gb`**
    
    - **Описание**: Объем памяти CPU, выделяемой для выгрузки данных.
    - **Пример значения**: `16` (выгрузка 16 ГБ данных на CPU).
    - **Когда использовать**: Если памяти GPU недостаточно для всей модели.
8. **`--swap-space`**
    
    - **Описание**: Объем пространства подкачки, который можно использовать.
    - **Пример значения**: `64` (64 ГБ пространства подкачки).
    - **Когда использовать**: Для обработки больших моделей или батчей.
9. **`--num-gpu-blocks-override`**
    
    - **Описание**: Принудительно задает количество блоков памяти на GPU.
    - **Пример значения**: `128`.
    - **Когда использовать**: Для ручного управления ресурсами GPU.

---

### **Настройки модели**

10. **`--dtype`**
    
    - **Описание**: Тип данных, используемых моделью.
    - **Допустимые значения**:
        - `float32`: Высокая точность.
        - `float16`: Уменьшает нагрузку на память и увеличивает скорость.
        - `bfloat16`: Баланс между точностью и производительностью.
    - **Когда использовать**: `float16` подходит для большинства задач.
11. **`--kv-cache-dtype`**
    
    - **Описание**: Тип данных для кэша ключ-значение.
    - **Допустимые значения**:
        - `auto`: Определяется автоматически.
        - `fp8`: Снижает использование памяти с помощью FP8.
    - **Когда использовать**: Если модель интенсивно использует кэш.
12. **`--quantization`**
    
    - **Описание**: Тип квантизации для модели.
    - **Допустимые значения**:
        - `aqlm`, `gptq`, `fp8`: Различные подходы к уменьшению размера модели.
    - **Когда использовать**: Для ускорения работы и уменьшения использования памяти.
13. **`--quantization-param-path`**
    
    - **Описание**: Указывает путь к файлу с параметрами квантизации.
    - **Пример значения**: `/path/to/quantization_params.json`.
    - **Когда использовать**: При использовании моделей с пользовательской квантизацией.
14. **`--max-model-len`**
    
    - **Описание**: Максимальная длина последовательности, которую может обрабатывать модель.
    - **Пример значения**: `2048`.
    - **Когда использовать**: Для ограничения длины входных данных.
15. **`--block-size`**
    
    - **Описание**: Размер блока для обработки модели.
    - **Допустимые значения**: `8`, `16`, `32`.
    - **Когда использовать**: Для тонкой настройки производительности.

---

### **Производительность обработки**

16. **`--max-num-batched-tokens`**
    
    - **Описание**: Максимальное количество токенов в одном батче.
    - **Пример значения**: `2048`.
    - **Когда использовать**: Для оптимизации размера входных данных.
17. **`--max-num-seqs`**
    
    - **Описание**: Максимальное количество последовательностей, обрабатываемых одновременно.
    - **Пример значения**: `32`.
    - **Когда использовать**: Для увеличения пропускной способности сервера.
18. **`--max-logprobs`**
    
    - **Описание**: Максимальное количество логарифмов вероятностей, которые модель должна вычислять.
    - **Пример значения**: `10`.
    - **Когда использовать**: Если нужно получать вероятности токенов.
19. **`--max-context-len-to-capture`**
    
    - **Описание**: Максимальная длина контекста, сохраняемого для анализа.
    - **Пример значения**: `2048`.
    - **Когда использовать**: Для управления объемом сохраняемой информации.
20. **`--enable-prefix-caching`**
    
    - **Описание**: Включает кэширование префиксов.
    - **Когда использовать**: Для ускорения обработки повторяющихся запросов.
21. **`--num-lookahead-slots`**
    
    - **Описание**: Количество слотов для предсказания следующих токенов.
    - **Пример значения**: `8`.
    - **Когда использовать**: Для повышения точности предсказаний.
22. **`--enforce-eager`**
    
    - **Описание**: Принудительно включает "жадный" (eager) режим вычислений.
    - **Когда использовать**: Для ускорения отладки и тестирования.






### **4. Настройка чата**

Параметры из этой группы управляют тем, как сервер обрабатывает взаимодействие с пользователем в формате чата. Они позволяют настроить формат общения, роль ответов и оптимизировать предварительную обработку данных.

---

### **Параметры для настройки чата**

1. **`--chat-template`**
    
    - **Описание**: Указывает путь к шаблону чата. Шаблон определяет, как сервер будет обрабатывать и форматировать сообщения от пользователя.
    - **Пример значения**: `/path/to/chat_template.json`.
    - **Когда использовать**:
        - Если нужно задать специфическую структуру диалога (например, для интеграции с системой, где ответы должны быть строго структурированными).
    - **Дополнительно**: Шаблон может быть в формате JSON или Jinja2 и использоваться для адаптации API под конкретные потребности клиента.
2. **`--response-role`**
    
    - **Описание**: Определяет роль, которую сервер будет использовать при отправке ответов.
    - **Пример значения**:
        - `assistant` — стандартная роль для ответов ИИ.
        - `system` — если сервер должен отвечать как системный процесс.
    - **Когда использовать**:
        - Если сервер работает в роли помощника, чат-бота или отвечает как системный агент.
3. **`--enable-chunked-prefill`**
    
    - **Описание**: Включает разбиение на части при предварительной загрузке (prefill). Это позволяет серверу обрабатывать сообщения кусками, что улучшает производительность и снижает задержки.
    - **Когда использовать**:
        - Если запросы содержат длинные сообщения.
        - При работе с моделями, требующими больших объемов предварительной обработки.

---

### **Что такое шаблон чата?**

Шаблон чата (`--chat-template`) помогает стандартизировать формат взаимодействия между пользователем и сервером. Например, вы можете определить, что входящее сообщение должно быть обернуто в структуру:

`{   "role": "user",   "content": "{{ message }}" }`

Или задать сложный формат, где сервер будет дополнять информацию из контекста:


```
{   "role": "assistant",   
	"content": "You asked about {{ topic }}. 
	Here is what I found: {{ response }}" }
```






### **Параметры работы с изображениями**

1. **`--image-input-type`**
    
    - **Описание**: Определяет тип входных данных для изображений.
    - **Допустимые значения**:
        - `pixel_values`: Передача пиксельных значений изображения в модель.
        - `image_features`: Передача предобработанных признаков изображения (например, извлеченных из другого модуля).
    - **Когда использовать**:
        - Если сервер принимает изображения для обработки или генерации на основе изображений.
2. **`--image-token-id`**
    
    - **Описание**: Указывает идентификатор токена, используемого для обозначения изображений в запросах.
    - **Пример значения**: `1024` (идентификатор токена изображения).
    - **Когда использовать**:
        - Если модель использует специальные токены для обозначения изображений в текстовом формате.
3. **`--image-input-shape`**
    
    - **Описание**: Задает форму входных изображений, которую принимает модель.
    - **Пример значения**: `[224, 224, 3]` (ширина, высота, число каналов).
    - **Когда использовать**:
        - Если сервер должен принимать изображения фиксированного размера.
4. **`--image-feature-size`**
    
    - **Описание**: Определяет размер признаков, которые модель ожидает для изображений.
    - **Пример значения**: `512` (количество извлекаемых признаков).
    - **Когда использовать**:
        - Если сервер принимает изображения в виде признаков, извлеченных из предварительно обученной модели.

---

### **Как это работает?**

Допустим, сервер работает с мультимодальной моделью, способной принимать как текст, так и изображения. Тогда запрос может выглядеть так:

`{   "text": "Describe this image:",   "image": "<image_data>" }`

Где `<image_data>` — это либо сырые пиксельные данные (при использовании `pixel_values`), либо предобработанные признаки (при использовании `image_features`).






### **6. Логирование и отладка**

Эта группа параметров помогает управлять логированием и отладкой работы сервера. Они важны для отслеживания ошибок, анализа производительности и оптимизации работы сервера.

---

### **Параметры логирования**

1. **`--disable-log-stats`**
    
    - **Описание**: Отключает сбор и вывод статистики логов.
    - **Когда использовать**:
        - Если сервер работает в продакшене, и сбор статистики увеличивает нагрузку.
2. **`--log-format`**
    
    - **Описание**: Определяет формат логов.
    - **Пример значения**:
        - `json`: Логи выводятся в формате JSON для интеграции с системами мониторинга.
        - `text`: Логи выводятся в читаемом текстовом формате.
    - **Когда использовать**:
        - Для интеграции с системами, такими как Elasticsearch или Kibana, используйте `json`.
        
3. **`--trace-log-directory`**
    
    - **Описание**: Указывает директорию для сохранения трассировочных логов.
    - **Пример значения**: `/var/log/vllm-traces/`.
    - **Когда использовать**:
        - Для глубокого анализа запросов, ошибок и производительности.
        
4. **`--max-log-len`**
    
    - **Описание**: Устанавливает максимальную длину логов для одного запроса.
    - **Пример значения**: `1000`.
    - **Когда использовать**:
        - Если запросы могут содержать большие данные, что приводит к переполнению логов.
        
---

### **Зачем это нужно?**

- **Отладка**: Вы можете отследить проблемы, возникающие при обработке запросов, включая ошибки в данных или настройках.
- **Анализ производительности**: Логи помогут выявить узкие места в производительности.
- **Интеграция с мониторингом**: Формат JSON удобен для систем мониторинга, таких как Prometheus, Grafana или ELK-стек.


### **7. Спекулятивное исполнение**

Эта группа параметров используется для настройки спекулятивного (предварительного) выполнения. Это полезно для оптимизации производительности модели при обработке длинных последовательностей, прогнозировании токенов или ускорении генерации ответов.

---

### **Параметры спекулятивного исполнения**

1. **`--speculative-model`**
    
    - **Описание**: Указывает модель, которая будет использоваться для спекулятивного выполнения. Спекулятивная модель обычно более легкая и быстрая, чем основная, и используется для генерации предварительных результатов.
    - **Пример значения**:
        - Имя модели: `gpt-neo-125M`.
        - Локальный путь: `/path/to/speculative_model/`.
    - **Когда использовать**:
        - Если вы хотите ускорить генерацию, используя менее ресурсоемкую модель для прогнозирования.
2. **`--num-speculative-tokens`**
    
    - **Описание**: Указывает количество токенов, которые будут предварительно сгенерированы спекулятивной моделью.
    - **Пример значения**: `32`.
    - **Когда использовать**:
        - При работе с длинными последовательностями, чтобы уменьшить задержки генерации.
3. **`--speculative-max-model-len`**
    
    - **Описание**: Максимальная длина последовательности, которая будет обработана спекулятивной моделью.
    - **Пример значения**: `1024`.
    - **Когда использовать**:
        - Если основной модели требуется обработать больше данных, чем может быть сгенерировано спекулятивной моделью за один раз.

---

### **Как работает спекулятивное исполнение?**

1. Основная идея заключается в использовании более быстрой модели для предсказания следующих токенов.
2. Эти токены передаются основной модели для уточнения или доработки.
3. Такой подход снижает общую задержку и ускоряет генерацию, особенно для длинных последовательностей.

---

### **Пример использования**

1. **С легкой спекулятивной моделью**:
    
    `vllm-openai-server --speculative-model gpt-neo-125M --num-speculative-tokens 64`
    
2. **Ограничение длины спекулятивной последовательности**:
    
    `vllm-openai-server --speculative-model gpt-neo-125M \                    --num-speculative-tokens 32 \                    --speculative-max-model-len 512`
    

---

### **Когда это полезно?**

- **Ускорение генерации**: Если основная модель тяжелая, но требуется быстрый ответ.
- **Снижение нагрузки**: Использование более легкой модели уменьшает использование памяти и процессорного времени.
- **Работа с длинными последовательностями**: Спекулятивная модель может быстрее обработать первую часть данных, что уменьшает задержки.

---

### **Ограничения**

- Спекулятивная модель должна быть достаточно хорошо обученной, чтобы её предсказания были полезными для основной модели.
- Некорректная настройка длины последовательности или количества токенов может привести к ухудшению качества генерации.



### **8. Прочие параметры**

Эта группа включает параметры, которые не относятся к конкретной функциональной категории, но предоставляют дополнительные возможности для тонкой настройки работы сервера. Эти параметры помогают улучшить стабильность, интеграцию с другими системами и управляемость сервера.

---

### **Параметры из группы**

1. **`--seed`**
    
    - **Описание**: Устанавливает начальное значение для генератора случайных чисел.
    - **Пример значения**: `42`.
    - **Когда использовать**:
        - Для воспроизводимости результатов, особенно при тестировании или отладке.
        
2. **`--scheduler-delay-factor`**
    
    - **Описание**: Устанавливает фактор задержки для планировщика задач.
    - **Пример значения**: `0.5`.
    - **Когда использовать**:
        - Для контроля времени ожидания между задачами, чтобы избежать перегрузки системы.
        
3. **`--use-v2-block-manager`**
    
    - **Описание**: Включает использование менеджера блоков версии 2, который может быть более эффективным для обработки данных.
    - **Когда использовать**:
        - Если сервер должен работать с большими блоками данных или высокими нагрузками.
        
4. **`--disable-custom-all-reduce`**
    
    - **Описание**: Отключает использование пользовательского метода `all-reduce` для распределенных вычислений.
    - **Когда использовать**:
        - Если возникают проблемы с распределенными вычислениями или используется нестандартная архитектура.

---

### **Когда использовать эту группу?**

Эти параметры полезны в следующих случаях:

- **Для воспроизводимости**: Установка начального значения генератора случайных чисел гарантирует, что результаты будут идентичными при повторном запуске.
- **Для оптимизации распределенных вычислений**: Например, при использовании `disable-custom-all-reduce` можно избежать конфликтов в сложных распределенных средах.
- **Для повышения стабильности**: Использование `scheduler-delay-factor` и `use-v2-block-manager` помогает сбалансировать нагрузку и предотвратить переполнение памяти.
